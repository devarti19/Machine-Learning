{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Process\n",
    "When people think of Machine Learning, they often think of a program that is taking in data and spitting out predictions and insights. The process of performing Machine Learning often requires many more steps before and after the predictive analytics."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><b>Formulating a Question</b>\n",
    "What is it that we want to find out? How will we reach the success criteria that we set?\n",
    "\n",
    "Let’s say we are performing machine learning for a high-traffic fast-casual restaurant chain, and our goal is to improve the customer experience. We can serve this goal in many ways. When we’re thinking about creating a model, we have to narrow down to one measurable, specific task. For example, we might say we want to predict the wait times for customers’ food orders within 2 minutes, so that we can give them an accurate time estimate.\n",
    "\n",
    "<li><b> Finding and Understanding the Data</b>\n",
    "Arguably the largest chunk of time in any machine learning process is finding the relevant data to help answer your question, and getting it into the format necessary for performing predictive analysis.\n",
    "\n",
    "We know that for supervised learning, we need labeled datasets, or datasets that have clear labels of what their ground truth is. For an example like the restaurant wait time, this would mean we would need many examples of past orders, tagged with how long the wait time was. Maybe the restaurant already tracks this data, but we might need to augment the data collection with a timer that starts when the customer orders, stops when the customer receives their food, and records that information.\n",
    "\n",
    "Creating this system of recording data, as well as gathering enough data to be able to train our model will take time.\n",
    "\n",
    "Once you have your data, you want to understand it so that you will know what model to apply and what the outputs will mean. First, you will want to examine the summary statistics:\n",
    "\n",
    "Calculate means and medians to understand the distribution\n",
    "Calculate percentiles\n",
    "Find correlations that indicate relationships\n",
    "You may also want to visualize the data, perhaps using box plots to identify outliers, histograms to show the basic structure of the data, and scatter plots to examine relationships between variables.\n",
    "\n",
    "Let’s say we’re examining the existing distribution of wait times. We see that the overall average is 6.25 minutes per order. But we also produce this histogram:\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "histogram of wait times\n",
    "\n",
    "We might glean from this that there are two main groups of orders. One group seems to cluster around 4 minutes, while another, smaller, group seems to cluster around 11 mins. We could use this to modify our question and build a model that will classify whether or not an order will be in this “short” timeframe, or in the “long” timeframe. Is it dependent on the food that it ordered? The time of day of the order?\n",
    "\n",
    "Perhaps we just become aware of the bimodality of our data. If our model consistently predicts a wait time of around 6 or 7 minutes, then we are not taking into account the true structure of our data.\n",
    "\n",
    "<li><b> Cleaning the Data and Feature Engineering</b>\n",
    "Real data is messy! Data may have errors. Some columns may be empty. The features we’re interested in might require string manipulation to extract. Cleaning the data refers to the process by which we address missing values and outliers, among other things that may affect our insights.\n",
    "\n",
    "We may see that we have a group of orders that took over 20 minutes, due to an emergency in the kitchen one afternoon. This is pushing our average wait time up, and may skew our predictions. If we want to model the more general functioning of the restaurant, we may want to remove these values.\n",
    "\n",
    "Feature Engineering refers to the process by which we choose the important features (or columns) to look at, and make the appropriate transformations to prepare our data for our model.\n",
    "\n",
    "We might try:\n",
    "\n",
    "Normalizing or standardizing the data\n",
    "Augmenting the data by adding new columns\n",
    "Removing unnecessary columns\n",
    "After we test our model on the data we have, we might go back and reengineer features to see if we get a better result.\n",
    "\n",
    "<li><b> Choosing a Model</b>\n",
    "Once we understand our dataset and know the problem we are trying to solve, we can begin to choose a model that will help us tackle our problem.\n",
    "\n",
    "If we are attempting to find a continuous output, like predicting the number of minutes someone should wait for their order, we would use a regression algorithm.\n",
    "\n",
    "If we are attempting to classify an input, like determining if an order will take under 5 minutes or over 10 mins, then we would use a classification algorithm.\n",
    "\n",
    "The different classification and regression algorithms work better on different types of datasets. We use different models on categorical and numerical data, and different models on datasets with many features and datasets with few features. Our models also have different levels of interpretability — how easy is it for us to see what these results mean and what led to them? When we teach the models, we will discuss the tradeoffs of using each one.\n",
    "<ul><b> Tuning and Evaluating</b>\n",
    "We often want to set a metric of success, so that we know the model we’ve chosen is good enough. Are we looking for accuracy? Precision? Some combination of the two? We discuss this in our lesson on Precision and Accuracy.\n",
    "\n",
    "Each model has a variety of parameters that change how it makes decisions. We can adjust these and compare the chosen evaluation metrics of the different variants to find the most accurate model.\n",
    "\n",
    "For example, let’s say we’re using a K-Nearest Neighbors regression algorithm to solve the wait time prediction problem. This algorithm uses a parameter k, which you will learn about in the KNN lesson. We can adjust k to get different results.\n",
    "\n",
    "Is it ideal to compare against 3 nearest neighbors? 10? 1? We can try many different values of k and see which one gives us the highest level of accuracy:\n",
    "![image.png](attachment:image.png)\n",
    "From this analysis, we would set our k to be 26, which got the highest level of accuracy.\n",
    "\n",
    "<ul><b>Using the Model and Presenting Results</b>\n",
    "When you achieve the level of accuracy you want on your training set, you can use the model on the data you actually care about analyzing.\n",
    "\n",
    "For our example, we can now start inputting new orders. The input could be an order, with features like:\n",
    "<ul>\n",
    "<li>the type of item ordered\n",
    "<li>the quantity\n",
    "<li>the time of day\n",
    "<li>the number of employees working\n",
    "    </ul>\n",
    "The output would be how long the order is expected to take. This information could be displayed to users.\n",
    "\n",
    "An important step is being able to convey what you’ve learned and created, so that people can use it in the future.\n",
    "\n",
    "Sometimes you learn more about your data by looking at the model. For example, using Multiple Learning Regression can give you insights into the importance of each feature. We can create a feature importance graph to visualize this for those unfamiliar with our model:\n",
    "![image.png](attachment:image.png)\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Process\n",
    "The process we have outlined is a fairly standard process for performing machine learning. As you get experience going through this process on your own, with your own problems, you will start to form your own process. The steps may not be linear! As you clean your data, you may uncover a better question to ask. As you tune your model, you may realize you need more data, and go back to the collection step.\n",
    "\n",
    "The important part is to stay curious, and to keep iterating until you find a model that works the best!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised vs. Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As humans, we have many different ways we learn things. The way you learned calculus, for example, is probably not the same way you learned to stack blocks. The way you learned the alphabet is probably wildly different from the way you learned how to tell if objects are approaching you or going away from you. The latter you might not even realize you learned at all!\n",
    "\n",
    "Similarly, when we think about making programs that can learn, we have to think about these programs learning in different ways. Two main ways that we can approach machine learning are Supervised Learning and Unsupervised Learning. Both are useful for different situations or kinds of data available.\n",
    "\n",
    "<b>Supervised Learning</b>\n",
    "Let’s imagine you’re first learning about different genres in music. Your music teacher plays you an indie rock song and says “This is an indie rock song”. Then, they play you a K-pop song and tell you “This is a K-pop song”. Then, they play you a techno track and say “This is techno”. You go through many examples of these genres.\n",
    "\n",
    "The next time you’re listening to the radio, and you hear techno, you may think “This is similar to the 5 techno tracks I heard in class today. This must be techno!”\n",
    "\n",
    "Even though the teacher didn’t tell you about this techno track, she gave you enough examples of songs that were techno, so you could recognize more examples of it.\n",
    "\n",
    "When we explicitly tell a program what we expect the output to be, and let it learn the rules that produce expected outputs from given inputs, we are performing supervised learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A common example of this is image classification. Often, we want to build systems that will be able to describe a picture. To do this, we normally show a program thousands of examples of pictures, with labels that describe them. During this process, the program adjusts its internal parameters. Then, when we show it a new example of a photo with an unknown description, it should be able to produce a reasonable description of the photo.\n",
    "\n",
    "When you complete a Captcha and identify the images that have cars, you’re labeling images! A supervised machine learning algorithm can now use those pictures that you’ve tagged to make it’s car-image predictor more accurate.\n",
    "\n",
    "<b>Unsupervised Learning</b>\n",
    "\n",
    "Let’s say you are an alien who has been observing the meals people eat. You’ve embedded yourself into the body of an employee at a typical tech startup, and you see people eating breakfasts, lunches, and snacks. Over the course of a couple weeks, you surmise that for breakfast people mostly eat foods like:\n",
    "\n",
    "Cereals\n",
    "Bagels\n",
    "Granola bars\n",
    "Lunch is usually a combination of:\n",
    "\n",
    "Some sort of vegetable\n",
    "Some sort of protein\n",
    "Some sort of grain\n",
    "Snacks are usually a piece of fruit or a handful of nuts. No one explicitly told you what kinds of foods go with each meal, but you learned from natural observation and put the patterns together. In unsupervised learning, we don’t tell the program anything about what we expect the output to be. The program itself analyzes the data it encounters and tries to pick out patterns and group the data in meaningful ways.\n",
    "\n",
    "Unsupervised Learning\n",
    "\n",
    "\n",
    "An example of this includes clustering to create segments in a business’s user population. In this case, an unsupervised learning algorithm would probably create groups (or clusters) based on parameters that a human may not even consider.\n",
    "\n",
    "Summary\n",
    "We have gone over the difference between supervised and unsupervised learning:\n",
    "\n",
    "Supervised Learning: data is labeled and the program learns to predict the output from the input data\n",
    "Unsupervised Learning: data is unlabeled and the program learns to recognize the inherent structure in the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "Scikit-learn is a library in Python that provides many unsupervised and supervised learning algorithms. It’s built upon some of the technology you might already be familiar with, like NumPy, pandas, and Matplotlib!\n",
    "\n",
    "The functionality that scikit-learn provides include:\n",
    "<ul>\n",
    "    <li><b>Regression</b>, including Linear and Logistic Regression\n",
    "    <li><b>Classification</b>, including K-Nearest Neighbors\n",
    "    <li><b>Clustering</b>, including K-Means and K-Means++\n",
    "    <li><b>Model selection</b>\n",
    "    <li><b>Preprocessing</b>, including Min-Max Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "Import and create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "your_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-db0b445cc316>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myour_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_training_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "your_model.fit(x_training_data, y_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>coef_: contains the`m coefficients\n",
    "<li>intercept_: contains the intercept\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = your_model.predict(your_x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".score(): returns the coefficient of determination R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "your_model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model.fit(x_training_data, y_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'your_x_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-374017c3e465>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Returns a list of predicted classes - one prediction for every data point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myour_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myour_x_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# For every data point, returns a list of probabilities of each class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myour_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myour_x_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'your_x_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Returns a list of predicted classes - one prediction for every data point\n",
    "predictions = your_model.predict(your_x_data)\n",
    "\n",
    "# For every data point, returns a list of probabilities of each class\n",
    "probabilities = your_model.predict_proba(your_x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neigbors import KNeighborsClassifier\n",
    "\n",
    "your_model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model.fit(x_training_data, y_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list of predicted classes - one prediction for every data point\n",
    "predictions = your_model.predict(your_x_data)\n",
    "\n",
    "# For every data point, returns a list of probabilities of each class\n",
    "probabilities = your_model.predict_proba(your_x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "your_model = KMeans(n_clusters=4, init='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>n_clusters: number of clusters to form and number of centroids to generate\n",
    "<li>init: method for initialization\n",
    "    <ul>\n",
    "<li>k-means++: K-Means++ [default]\n",
    "<li>random: K-Means\n",
    "    </ul>\n",
    "<li>random_state: the seed used by the random number generator [optional]\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_model.fit(x_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = your_model.predict(your_x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(accuracy_score(true_labels, guesses))\n",
    "print(recall_score(true_labels, guesses))\n",
    "print(precision_score(true_labels, guesses))\n",
    "print(f1_score(true_labels, guesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(true_labels, guesses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Sets and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>train_size: the proportion of the dataset to include in the train split\n",
    "<li>test_size: the proportion of the dataset to include in the test split\n",
    "<li>random_state: the seed used by the random number generator `m[optional]\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
