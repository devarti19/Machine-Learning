{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with a dataset “NewsArticles.json” having news articles of mixed topics including business, entertainment, politics, sports, technology, but without labels. \n",
    "You are required to make a clustering-based model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_json('C:/Users/91758/Downloads/training-NewsArticles/NewsArticles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Preprocessed-Article</th>\n",
       "      <th>Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musical treatment for Capra film\\n\\nThe classi...</td>\n",
       "      <td>Musical treatment Capra film The classic film ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spark heads world Booker list\\n\\nDame Muriel S...</td>\n",
       "      <td>Spark heads world Booker list Dame Muriel Spar...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Artists' secret postcards on sale\\n\\nPostcards...</td>\n",
       "      <td>Artists  secret postcards sale Postcards artis...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Chepkemei joins Edinburgh line-up\\n\\nSusan Che...</td>\n",
       "      <td>Chepkemei joins Edinburgh lineup Susan Chepkem...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>El Guerrouj targets cross country\\n\\nDouble Ol...</td>\n",
       "      <td>El Guerrouj targets cross country Double Olymp...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Article  \\\n",
       "0    Musical treatment for Capra film\\n\\nThe classi...   \n",
       "1    Spark heads world Booker list\\n\\nDame Muriel S...   \n",
       "10   Artists' secret postcards on sale\\n\\nPostcards...   \n",
       "100  Chepkemei joins Edinburgh line-up\\n\\nSusan Che...   \n",
       "101  El Guerrouj targets cross country\\n\\nDouble Ol...   \n",
       "\n",
       "                                  Preprocessed-Article  \\\n",
       "0    Musical treatment Capra film The classic film ...   \n",
       "1    Spark heads world Booker list Dame Muriel Spar...   \n",
       "10   Artists  secret postcards sale Postcards artis...   \n",
       "100  Chepkemei joins Edinburgh lineup Susan Chepkem...   \n",
       "101  El Guerrouj targets cross country Double Olymp...   \n",
       "\n",
       "                                                Vector  \n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "10   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "100  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "101  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector= df['Vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordf=pd.DataFrame(list(df_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>8858</th>\n",
       "      <th>8859</th>\n",
       "      <th>8860</th>\n",
       "      <th>8861</th>\n",
       "      <th>8862</th>\n",
       "      <th>8863</th>\n",
       "      <th>8864</th>\n",
       "      <th>8865</th>\n",
       "      <th>8866</th>\n",
       "      <th>8867</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8868 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  8858  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   8859  8860  8861  8862  8863  8864  8865  8866  8867  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8868 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 8868)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "km= KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(vectordf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=pd.Series(km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68\n",
       "1    37\n",
       "3    33\n",
       "4    22\n",
       "2    19\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164.38211020849118"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.inertia_ #SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label']= km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelname 0\n",
      "['euniversity', 'disgraceful', 'waste', 'a', 'failed', 'government', 'scheme', 'offer', 'uk', 'university', 'courses', 'online', 'branded', 'disgraceful', 'waste', 'mps', 'the', 'euniversity', 'scrapped', 'last', 'year', 'attracted', '900', 'students', 'cost', '£50m', 'chief', 'executive', 'john', 'beaumont', 'paid', 'bonus', '£44914', 'despite', 'failure', 'bring', 'private', 'sector', 'backers', 'the', 'commons', 'education', 'select', 'committee', 'called', 'morally', 'indefensible', 'government', 'said', 'euniversity']\n",
      "labelname 1\n",
      "['tsunami', 'debt', 'deal', 'announced', 'chancellor', 'gordon', 'brown', 'said', 'hopes', 'announce', 'deal', 'suspend', 'debt', 'interest', 'repayments', 'tsunamihit', 'nations', 'later', 'friday', 'the', 'agreement', 'g8', 'group', 'wealthy', 'nations', 'would', 'save', 'affected', 'countries', '£3bn', 'pounds', 'year', 'said', 'the', 'deal', 'thought', 'hammered', 'thursday', 'night', 'japan', 'one', 'biggest', 'creditor', 'nations', 'finally', 'signed', 'mr', 'brown', 'first', 'proposed']\n",
      "labelname 2\n",
      "['sprinter', 'walker', 'quits', 'athletics', 'former', 'european', '200m', 'champion', 'dougie', 'walker', 'retire', 'athletics', 'series', 'six', 'operations', 'left', 'struggling', 'fitness', 'walker', 'hoped', 'compete', 'new', 'year', 'sprint', 'staged', 'musselburgh', 'racecourse', 'near', 'edinburgh', 'tuesday', 'wednesday', 'the', '31yearold', 'scot', 'suspended', 'two', 'years', '1998', 'testing', 'positive', 'nandrolone', 'i', 'intended', 'race', 'i', 'running', 'like', 'goon', 'said', 'walker']\n",
      "labelname 3\n",
      "['musical', 'treatment', 'capra', 'film', 'the', 'classic', 'film', 'it', 'a', 'wonderful', 'life', 'turned', 'musical', 'producer', 'controversial', 'hit', 'show', 'jerry', 'springer', 'the', 'opera', 'frank', 'capra', '1946', 'movie', 'starring', 'james', 'stewart', 'turned', '£7m', 'musical', 'producer', 'jon', 'thoday', 'he', 'working', 'steve', 'brown', 'wrote', 'awardwinning', 'musical', 'spend', 'spend', 'spend', 'a', 'spokeswoman', 'said', 'plans', 'early', 'stages']\n",
      "labelname 4\n",
      "['chepkemei', 'joins', 'edinburgh', 'lineup', 'susan', 'chepkemei', 'decided', 'fit', 'enough', 'run', 'next', 'month', 'great', 'edinburgh', 'international', 'cross', 'country', 'the', 'kenyan', 'initially', 'unsure', 'would', 'recovered', 'gruelling', 'tussle', 'paula', 'radcliffe', 'new', 'york', 'marathon', 'time', 'compete', 'but', 'declared', 'task', 'joins', 'field', 'headed', 'world', 'cross', 'country', 'champion', 'benita', 'johnson', 'race', 'director', 'matthew', 'turnbull', 'said', 'susan']\n"
     ]
    }
   ],
   "source": [
    "for each,subset in df.groupby(\"Label\"):\n",
    "    print('labelname',each)\n",
    "    print(' '.join(subset['Preprocessed-Article']).lower().split()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pca.fit_transform(vectordf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "km1=KMeans(n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km1.fit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.26676447236264"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km1.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    118\n",
       "4     23\n",
       "1     16\n",
       "3     11\n",
       "0     11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=pd.Series(km1.labels_)\n",
    "s.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WithPCALabel']= km1.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelname 0\n",
      "['holmes', 'feted', 'honour', 'double', 'olympic', 'champion', 'kelly', 'holmes', 'voted', 'european', 'athletics', 'eaa', 'woman', 'athlete', '2004', 'governing', 'body', 'annual', 'poll', 'the', 'briton', 'made', 'dame', 'new', 'year', 'honours', 'list', 'taking', '800m', '1500m', 'gold', 'vital', 'votes', 'public', 'press', 'eaa', 'member', 'federations', 'she', 'second', 'british', 'woman', 'land', 'title', 'sally', 'gunnell', 'world', '400m', 'hurdles', 'win']\n",
      "labelname 1\n",
      "['china', 'net', 'cafe', 'culture', 'crackdown', 'chinese', 'authorities', 'closed', '12575', 'net', 'cafes', 'closing', 'months', '2004', 'country', 'government', 'said', 'according', 'official', 'news', 'agency', 'net', 'cafes', 'closed', 'operating', 'illegally', 'chinese', 'net', 'cafes', 'operate', 'set', 'strict', 'guidelines', 'many', 'recently', 'closed', 'broke', 'rules', 'limit', 'close', 'schools', 'the', 'move', 'latest', 'series', 'steps', 'chinese', 'government', 'taken', 'crack']\n",
      "labelname 2\n",
      "['musical', 'treatment', 'capra', 'film', 'the', 'classic', 'film', 'it', 'a', 'wonderful', 'life', 'turned', 'musical', 'producer', 'controversial', 'hit', 'show', 'jerry', 'springer', 'the', 'opera', 'frank', 'capra', '1946', 'movie', 'starring', 'james', 'stewart', 'turned', '£7m', 'musical', 'producer', 'jon', 'thoday', 'he', 'working', 'steve', 'brown', 'wrote', 'awardwinning', 'musical', 'spend', 'spend', 'spend', 'a', 'spokeswoman', 'said', 'plans', 'early', 'stages']\n",
      "labelname 3\n",
      "['richard', 'judy', 'choose', 'top', 'books', 'the', '10', 'authors', 'shortlisted', 'richard', 'judy', 'book', 'award', '2005', 'hoping', 'boost', 'sales', 'following', 'success', 'year', 'winner', 'the', 'tv', 'couple', 'interest', 'book', 'world', 'coined', 'term', 'richard', 'judy', 'effect', 'created', 'top', 'two', 'bestselling', 'paperbacks', '2004', 'far', 'the', 'finalists', '2005', 'include', 'andrew', 'taylor', 'the', 'american', 'boy', 'robbie', 'williams']\n",
      "labelname 4\n",
      "['chepkemei', 'joins', 'edinburgh', 'lineup', 'susan', 'chepkemei', 'decided', 'fit', 'enough', 'run', 'next', 'month', 'great', 'edinburgh', 'international', 'cross', 'country', 'the', 'kenyan', 'initially', 'unsure', 'would', 'recovered', 'gruelling', 'tussle', 'paula', 'radcliffe', 'new', 'york', 'marathon', 'time', 'compete', 'but', 'declared', 'task', 'joins', 'field', 'headed', 'world', 'cross', 'country', 'champion', 'benita', 'johnson', 'race', 'director', 'matthew', 'turnbull', 'said', 'susan']\n"
     ]
    }
   ],
   "source": [
    "for each,subset in df.groupby(\"WithPCALabel\"):\n",
    "    print('labelname',each)\n",
    "    print(\"\".join(subset['Preprocessed-Article']).lower().split()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
